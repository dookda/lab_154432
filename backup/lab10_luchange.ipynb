{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ee\n",
    "!pip install geemap\n",
    "!pip install geopandas\n",
    "!pip install rasterio\n",
    "!pip install numpy\n",
    "!pip install shapely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentinel2TiledDownloader:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Earth Engine\"\"\"\n",
    "        try:\n",
    "            ee.Initialize()\n",
    "        except:\n",
    "            ee.Authenticate()\n",
    "            ee.Initialize()\n",
    "    \n",
    "    def load_and_tile_study_area(self, shapefile_path, n_tiles=4):\n",
    "       \n",
    "        gdf = gpd.read_file(shapefile_path)\n",
    "        \n",
    "        # Convert to WGS84 if needed\n",
    "        if gdf.crs != 'EPSG:4326':\n",
    "            gdf = gdf.to_crs('EPSG:4326')\n",
    "        \n",
    "        # Get bounds\n",
    "        minx, miny, maxx, maxy = gdf.total_bounds\n",
    "        \n",
    "        # Calculate tile sizes\n",
    "        n_tiles_per_side = int(np.ceil(np.sqrt(n_tiles)))\n",
    "        tile_width = (maxx - minx) / n_tiles_per_side\n",
    "        tile_height = (maxy - miny) / n_tiles_per_side\n",
    "        \n",
    "        # Create tiles\n",
    "        tiles = []\n",
    "        for i in range(n_tiles_per_side):\n",
    "            for j in range(n_tiles_per_side):\n",
    "                # Calculate tile bounds\n",
    "                tile_minx = minx + (i * tile_width)\n",
    "                tile_miny = miny + (j * tile_height)\n",
    "                tile_maxx = tile_minx + tile_width\n",
    "                tile_maxy = tile_miny + tile_height\n",
    "                \n",
    "                # Create tile geometry\n",
    "                tile_box = box(tile_minx, tile_miny, tile_maxx, tile_maxy)\n",
    "                tile_gdf = gpd.GeoDataFrame(geometry=[tile_box], crs='EPSG:4326')\n",
    "                \n",
    "                # Clip with original study area\n",
    "                tile_gdf = gpd.overlay(tile_gdf, gdf, how='intersection')\n",
    "                \n",
    "                # Add tile if it's not empty\n",
    "                if not tile_gdf.empty:\n",
    "                    tiles.append(tile_gdf)\n",
    "        \n",
    "        print(f\"Created {len(tiles)} tiles from study area\")\n",
    "        return tiles\n",
    "    \n",
    "    def check_data_availability(self, geometry, start_date, end_date, max_cloud_cover=80):\n",
    "        \"\"\"\n",
    "        Check if data is available for the given parameters\n",
    "        Returns the filtered collection and count of images\n",
    "        \"\"\"\n",
    "        ee_geometry = ee.Geometry.Polygon(\n",
    "            geometry.__geo_interface__['features'][0]['geometry']['coordinates'])\n",
    "        \n",
    "        # Get initial collection with relaxed cloud cover\n",
    "        collection = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "            .filterBounds(ee_geometry)\n",
    "            .filterDate(start_date, end_date))\n",
    "        \n",
    "        # Get count of all images\n",
    "        total_count = collection.size().getInfo()\n",
    "        \n",
    "        # Apply cloud cover filter\n",
    "        filtered_collection = collection.filter(\n",
    "            ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "        filtered_count = filtered_collection.size().getInfo()\n",
    "        \n",
    "        return filtered_collection, total_count, filtered_count, ee_geometry\n",
    "\n",
    "    def get_best_image_composite(self, collection, max_images=10):\n",
    "        sorted_collection = collection.sort('CLOUDY_PIXEL_PERCENTAGE')\n",
    "        \n",
    "        # Take best N images\n",
    "        best_images = sorted_collection.limit(max_images)\n",
    "        \n",
    "        # Create composite\n",
    "        composite = best_images.median()\n",
    "        \n",
    "        # Select bands\n",
    "        selected_bands = ['B2', 'B3', 'B4', 'B8']\n",
    "        return composite.select(selected_bands)\n",
    "\n",
    "def download_with_retry(shapefile_path, year, output_folder, n_tiles=4):\n",
    "    downloader = Sentinel2TiledDownloader()\n",
    "    tiles = downloader.load_and_tile_study_area(shapefile_path, n_tiles)\n",
    "    \n",
    "    # Strategy parameters\n",
    "    cloud_covers = [20, 30, 50, 80]  # Progressively relaxed cloud coverage\n",
    "    date_ranges = [\n",
    "        (f'{year}-05-01', f'{year}-09-30'),  # Initial range\n",
    "        (f'{year}-01-01', f'{year}-12-31'),  # Full year\n",
    "        (f'{year-1}-12-01', f'{year+1}-01-31')  # Extended range\n",
    "    ]\n",
    "    \n",
    "    successful_tiles = []\n",
    "    \n",
    "    for tile_idx, tile in enumerate(tiles):\n",
    "        tile_downloaded = False\n",
    "        \n",
    "        for date_start, date_end in date_ranges:\n",
    "            if tile_downloaded:\n",
    "                break\n",
    "                \n",
    "            for cloud_cover in cloud_covers:\n",
    "                try:\n",
    "                    print(f\"\\nTrying tile {tile_idx + 1}/{len(tiles)}\")\n",
    "                    print(f\"Date range: {date_start} to {date_end}\")\n",
    "                    print(f\"Max cloud cover: {cloud_cover}%\")\n",
    "                    \n",
    "                    # Check data availability\n",
    "                    collection, total, filtered, ee_geometry = downloader.check_data_availability(\n",
    "                        tile, date_start, date_end, cloud_cover)\n",
    "                    \n",
    "                    print(f\"Found {total} total images, {filtered} after cloud filtering\")\n",
    "                    \n",
    "                    if filtered > 0:\n",
    "                        # Create and download composite\n",
    "                        composite = downloader.get_best_image_composite(collection)\n",
    "                        \n",
    "                        tile_path = os.path.join(\n",
    "                            output_folder, \n",
    "                            f'sentinel2_{year}_tile_{tile_idx}.tif'\n",
    "                        )\n",
    "                        \n",
    "                        url = composite.getDownloadURL({\n",
    "                            'scale': 10,\n",
    "                            'crs': 'EPSG:4326',\n",
    "                            'region': ee_geometry,\n",
    "                            'format': 'GEO_TIFF'\n",
    "                        })\n",
    "                        \n",
    "                        geemap.download_file(url, tile_path)\n",
    "                        successful_tiles.append(tile_path)\n",
    "                        tile_downloaded = True\n",
    "                        print(f\"Successfully downloaded tile {tile_idx + 1}\")\n",
    "                        break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error with current parameters: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if not tile_downloaded:\n",
    "            print(f\"Failed to download tile {tile_idx + 1} with all retry strategies\")\n",
    "    \n",
    "    # Merge successful tiles\n",
    "    if successful_tiles:\n",
    "        try:\n",
    "            src_files = [rasterio.open(path) for path in successful_tiles]\n",
    "            mosaic, out_transform = merge(src_files)\n",
    "            \n",
    "            out_meta = src_files[0].meta.copy()\n",
    "            out_meta.update({\n",
    "                \"height\": mosaic.shape[1],\n",
    "                \"width\": mosaic.shape[2],\n",
    "                \"transform\": out_transform\n",
    "            })\n",
    "            \n",
    "            output_path = os.path.join(output_folder, f'sentinel2_{year}_merged.tif')\n",
    "            with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "                dest.write(mosaic)\n",
    "            \n",
    "            for src in src_files:\n",
    "                src.close()\n",
    "            \n",
    "            # Clean up individual tiles\n",
    "            for path in successful_tiles:\n",
    "                os.remove(path)\n",
    "            \n",
    "            print(f\"\\nSuccessfully merged {len(successful_tiles)} tiles\")\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error merging tiles: {str(e)}\")\n",
    "            return successful_tiles\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    shapefile_path = os.path.join(os.getcwd(), 'data/meatha.shp')\n",
    "    output_folder = \"sentinel2_data\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    result = download_with_retry(\n",
    "        shapefile_path=shapefile_path,\n",
    "        year=2022,\n",
    "        output_folder=output_folder,\n",
    "        n_tiles=9  # Adjust based on your area size\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(\"Download completed successfully\")\n",
    "    else:\n",
    "        print(\"Download failed for all tiles\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    shapefile_path = os.path.join(os.getcwd(), 'data/meatha.shp')\n",
    "    output_folder = \"sentinel2_data\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    result = download_with_retry(\n",
    "        shapefile_path=shapefile_path,\n",
    "        year=2022,\n",
    "        output_folder=output_folder,\n",
    "        n_tiles=9  # Adjust based on your area size\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(\"Download completed successfully\")\n",
    "    else:\n",
    "        print(\"Download failed for all tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install rasterio\n",
    "!pip install folium\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import folium\n",
    "from folium import plugins\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandUseAnalysis:\n",
    "    def __init__(self, shapefile_path):\n",
    "        \"\"\"\n",
    "        กำหนดค่าเริ่มต้นสำหรับการวิเคราะห์\n",
    "        \"\"\"\n",
    "        self.study_area = gpd.read_file(shapefile_path)\n",
    "        self.land_use_categories = {\n",
    "            1: 'พื้นที่เกษตรกรรม',\n",
    "            2: 'พื้นที่ป่าไม้',\n",
    "            3: 'พื้นที่เมือง',\n",
    "            4: 'แหล่งน้ำ',\n",
    "            5: 'พื้นที่อื่นๆ'\n",
    "        }\n",
    "    \n",
    "    def load_satellite_data(self, raster_path, year):\n",
    "        \"\"\"\n",
    "        โหลดข้อมูลภาพถ่ายดาวเทียม\n",
    "        \"\"\"\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            self.satellite_data = src.read()\n",
    "            self.metadata = src.meta\n",
    "            self.year = year\n",
    "    \n",
    "    def classify_land_use(self):\n",
    "        \"\"\"\n",
    "        จำแนกประเภทการใช้ประโยชน์ที่ดิน\n",
    "        \"\"\"\n",
    "        # สมมติว่าใช้วิธีการจำแนกแบบง่าย (ในความเป็นจริงควรใช้ machine learning)\n",
    "        classified = np.zeros_like(self.satellite_data[0])\n",
    "        \n",
    "        # ตัวอย่างการจำแนกอย่างง่าย\n",
    "        ndvi = (self.satellite_data[3] - self.satellite_data[2]) / (self.satellite_data[3] + self.satellite_data[2])\n",
    "        \n",
    "        classified[ndvi > 0.5] = 2  # ป่าไม้\n",
    "        classified[ndvi < 0] = 4    # แหล่งน้ำ\n",
    "        classified[(ndvi >= 0) & (ndvi <= 0.2)] = 3  # เมือง\n",
    "        classified[(ndvi > 0.2) & (ndvi <= 0.5)] = 1  # เกษตรกรรม\n",
    "        \n",
    "        self.classified_data = classified\n",
    "\n",
    "        # save classified data to file with output prefix 'classified_data'\n",
    "        with rasterio.open('classified_data.tif', 'w', **self.metadata) as dst:\n",
    "            dst.write(classified, 1)\n",
    "\n",
    "        return classified\n",
    "    \n",
    "    def calculate_area_statistics(self):\n",
    "        \"\"\"\n",
    "        คำนวณสถิติพื้นที่แต่ละประเภท\n",
    "        \"\"\"\n",
    "        stats = {}\n",
    "        pixel_area = abs(self.metadata['transform'][0] * self.metadata['transform'][4])\n",
    "        \n",
    "        for code, name in self.land_use_categories.items():\n",
    "            area = np.sum(self.classified_data == code) * pixel_area\n",
    "            percentage = (area / (self.metadata['width'] * self.metadata['height'] * pixel_area)) * 100\n",
    "            stats[name] = {\n",
    "                'area_sq_km': area / 1000000,  # แปลงเป็น ตร.กม.\n",
    "                'percentage': percentage\n",
    "            }\n",
    "        \n",
    "        return pd.DataFrame(stats).T\n",
    "    \n",
    "    def create_change_matrix(self, old_classification, new_classification):\n",
    "        \"\"\"\n",
    "        สร้าง matrix แสดงการเปลี่ยนแปลงการใช้ประโยชน์ที่ดิน\n",
    "        \"\"\"\n",
    "        matrix = confusion_matrix(old_classification.flatten(), \n",
    "                                new_classification.flatten(),\n",
    "                                labels=list(self.land_use_categories.keys()))\n",
    "        \n",
    "        df_matrix = pd.DataFrame(matrix,\n",
    "                               index=[f'From {v}' for v in self.land_use_categories.values()],\n",
    "                               columns=[f'To {v}' for v in self.land_use_categories.values()])\n",
    "        return df_matrix\n",
    "    \n",
    "    def plot_results(self):\n",
    "        \"\"\"\n",
    "        สร้างแผนที่และกราฟแสดงผลการวิเคราะห์\n",
    "        \"\"\"\n",
    "         # ตรวจสอบระบบปฏิบัติการ\n",
    "        if os.name == 'nt':  # Windows\n",
    "            # ลองใช้ fonts ที่มักมีในเครื่อง Windows\n",
    "            font_paths = [\n",
    "                'c:/Windows/Fonts/THSarabunNew.ttf',\n",
    "                'c:/Windows/Fonts/Tahoma.ttf',\n",
    "                'c:/Windows/Fonts/THSarabun.ttf',\n",
    "                'c:/Windows/Fonts/Angsana.ttf'\n",
    "            ]\n",
    "        else:  # MacOS และ Linux\n",
    "            font_paths = [\n",
    "                '/usr/share/fonts/thai/THSarabunNew.ttf',\n",
    "                '/Library/Fonts/THSarabunNew.ttf',\n",
    "                '/usr/share/fonts/truetype/thai/Sarabun-Regular.ttf'\n",
    "            ]\n",
    "\n",
    "        # ค้นหา font ที่ใช้ได้\n",
    "        font_path = None\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                font_path = path\n",
    "                break\n",
    "\n",
    "        if font_path:\n",
    "            # กำหนด font\n",
    "            font_prop = fm.FontProperties(fname=font_path)\n",
    "            plt.rcParams['font.family'] = font_prop.get_name()\n",
    "        else:\n",
    "            # ถ้าไม่พบ font ภาษาไทย ให้ใช้ Microsoft Sans Serif\n",
    "            plt.rcParams['font.family'] = 'Microsoft Sans Serif'\n",
    "\n",
    "        # ตั้งค่าเพิ่มเติมเพื่อรองรับภาษาไทย\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # แผนที่การใช้ประโยชน์ที่ดิน\n",
    "        im = ax1.imshow(self.classified_data, cmap='Set3')\n",
    "        ax1.set_title(f'การใช้ประโยชน์ที่ดิน ปี {self.year}')\n",
    "        \n",
    "        # สร้าง legend\n",
    "        patches = [plt.plot([], [], marker=\"s\", ms=10, ls=\"\", color=plt.cm.Set3(i/5.), \n",
    "                          label=name)[0] for i, name in self.land_use_categories.items()]\n",
    "        ax1.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        \n",
    "        # กราฟแสดงสัดส่วนพื้นที่\n",
    "        stats = self.calculate_area_statistics()\n",
    "        stats['percentage'].plot(kind='bar', ax=ax2)\n",
    "        ax2.set_title('สัดส่วนการใช้ประโยชน์ที่ดิน')\n",
    "        ax2.set_ylabel('ร้อยละ')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(shapefile_path, raster_path_2010, raster_path_2020):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันหลักสำหรับการวิเคราะห์\n",
    "    \"\"\"\n",
    "\n",
    "    # สร้าง instance สำหรับการวิเคราะห์\n",
    "    analysis = LandUseAnalysis(shapefile_path)\n",
    "\n",
    "    # วิเคราะห์ข้อมูลปี 2010\n",
    "    analysis.load_satellite_data(raster_path_2010, 2010)\n",
    "    classification_2010 = analysis.classify_land_use()\n",
    "    stats_before = analysis.calculate_area_statistics()\n",
    "    \n",
    "    # วิเคราะห์ข้อมูลปี 2020\n",
    "    analysis.load_satellite_data(raster_path_2020, 2020)\n",
    "    classification_2020 = analysis.classify_land_use()\n",
    "    stats_after = analysis.calculate_area_statistics()\n",
    "    \n",
    "    # วิเคราะห์การเปลี่ยนแปลง\n",
    "    change_matrix = analysis.create_change_matrix(classification_2010, classification_2020)\n",
    "    \n",
    "    # สร้างแผนที่และกราฟ\n",
    "    fig = analysis.plot_results()\n",
    "    \n",
    "    return stats_before, stats_after, change_matrix, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stats_before, stats_after, change_matrix, figures = run_analysis(\n",
    "        'data/meatha.shp',\n",
    "        'sentinel2_data/sentinel2_2020_merged.tif',\n",
    "        'sentinel2_data/sentinel2_2022_merged.tif'\n",
    "    )\n",
    "\n",
    "    print(\"สถิติพื้นที่ปี 2020\")\n",
    "    print(stats_before)\n",
    "    print(\"\\nสถิติพื้นที่ปี 2022\")\n",
    "    print(stats_after)\n",
    "    print(\"\\nMatrix การเปลี่ยนแปลง\")\n",
    "    print(change_matrix)\n",
    "\n",
    "\n",
    "    # show statistics in a table\n",
    "    stats_before.style.background_gradient(cmap='viridis', axis=0)\n",
    "\n",
    "    stats_after.style.background_gradient(cmap='viridis', axis=0)\n",
    "\n",
    "    change_matrix.style.background_gradient(cmap='viridis', axis=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
